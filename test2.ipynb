{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c64a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features: 23\n",
      "Dataset size: 7810\n",
      "\n",
      "Applying advanced feature engineering...\n",
      "Features after engineering: 39\n",
      "\n",
      "Numeric features: 30\n",
      "Categorical features: 6\n",
      "\n",
      "======================================================================\n",
      "BUILDING OPTIMIZED SUPER ENSEMBLE WITH 6 MODELS\n",
      "======================================================================\n",
      "\n",
      "Training individual models...\n",
      "\n",
      "Training XGBoost...\n",
      "XGBoost Validation Accuracy: 0.980695\n",
      "\n",
      "Training LightGBM...\n",
      "LightGBM Validation Accuracy: 0.980695\n",
      "\n",
      "Training CatBoost...\n",
      "CatBoost Validation Accuracy: 0.989704\n",
      "\n",
      "Training RandomForest...\n",
      "RandomForest Validation Accuracy: 0.985843\n",
      "\n",
      "Training ExtraTrees...\n",
      "ExtraTrees Validation Accuracy: 0.985843\n",
      "\n",
      "Training GradientBoosting...\n",
      "GradientBoosting Validation Accuracy: 0.990991\n",
      "\n",
      "======================================================================\n",
      "CREATING WEIGHTED VOTING ENSEMBLE\n",
      "======================================================================\n",
      "\n",
      "Retraining all models on full data...\n",
      "XGBoost trained\n",
      "LightGBM trained\n",
      "CatBoost trained\n",
      "RandomForest trained\n",
      "ExtraTrees trained\n",
      "GradientBoosting trained\n",
      "\n",
      "Model Weights:\n",
      "  XGBoost: 0.1658 (Val Acc: 0.980695)\n",
      "  LightGBM: 0.1658 (Val Acc: 0.980695)\n",
      "  CatBoost: 0.1674 (Val Acc: 0.989704)\n",
      "  RandomForest: 0.1667 (Val Acc: 0.985843)\n",
      "  ExtraTrees: 0.1667 (Val Acc: 0.985843)\n",
      "  GradientBoosting: 0.1676 (Val Acc: 0.990991)\n",
      "\n",
      "======================================================================\n",
      "ENSEMBLE VALIDATION ACCURACY: 0.990991\n",
      "======================================================================\n",
      "\n",
      "Submission saved: submission_test2_optimized.csv (2630 rows)\n",
      "Prediction distribution:\n",
      "0    1893\n",
      "1     737\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths\n",
    "train_path = \"Train_Dataset.csv\"\n",
    "test_path = \"Test_Dataset.csv\"\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "target_col = \"Attrition\"\n",
    "id_col = \"EmployeeID\"\n",
    "\n",
    "# Remove rows with missing target values\n",
    "train_df = train_df[train_df[target_col].notna()].copy()\n",
    "\n",
    "# Encode target if needed\n",
    "if train_df[target_col].dtype == 'object':\n",
    "    le = LabelEncoder()\n",
    "    train_df[target_col] = le.fit_transform(train_df[target_col])\n",
    "\n",
    "# Combine for feature engineering\n",
    "train_df['is_train'] = 1\n",
    "test_df['is_train'] = 0\n",
    "combined_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"Original features: {combined_df.shape[1]}\")\n",
    "print(f\"Dataset size: {len(combined_df)}\")\n",
    "\n",
    "# ============================================\n",
    "# ADVANCED FEATURE ENGINEERING\n",
    "# ============================================\n",
    "\n",
    "def create_advanced_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Salary features\n",
    "    if 'MonthlyIncome' in df.columns and 'Age' in df.columns:\n",
    "        df['IncomePerAge'] = df['MonthlyIncome'] / (df['Age'] + 1)\n",
    "    \n",
    "    if 'MonthlyIncome' in df.columns and 'YearsAtCompany' in df.columns:\n",
    "        df['IncomePerYear'] = df['MonthlyIncome'] / (df['YearsAtCompany'] + 1)\n",
    "    \n",
    "    if 'HourlyRate' in df.columns and 'MonthlyRate' in df.columns:\n",
    "        df['TotalRate'] = df['HourlyRate'] + df['MonthlyRate']\n",
    "        df['RateRatio'] = df['HourlyRate'] / (df['MonthlyRate'] + 1)\n",
    "    \n",
    "    if 'DailyRate' in df.columns and 'MonthlyRate' in df.columns:\n",
    "        df['DailyMonthlyRatio'] = df['DailyRate'] / (df['MonthlyRate'] + 1)\n",
    "    \n",
    "    # Experience features\n",
    "    if 'TotalWorkingYears' in df.columns and 'Age' in df.columns:\n",
    "        df['ExperienceRatio'] = df['TotalWorkingYears'] / (df['Age'] + 1)\n",
    "        df['YearsNotWorking'] = df['Age'] - df['TotalWorkingYears'] - 18  # Assuming 18 is working start age\n",
    "    \n",
    "    if 'YearsAtCompany' in df.columns and 'TotalWorkingYears' in df.columns:\n",
    "        df['CompanyTenureRatio'] = df['YearsAtCompany'] / (df['TotalWorkingYears'] + 1)\n",
    "    \n",
    "    if 'YearsInCurrentRole' in df.columns and 'YearsAtCompany' in df.columns:\n",
    "        df['RoleTenureRatio'] = df['YearsInCurrentRole'] / (df['YearsAtCompany'] + 1)\n",
    "    \n",
    "    if 'YearsSinceLastPromotion' in df.columns and 'YearsAtCompany' in df.columns:\n",
    "        df['PromotionRatio'] = df['YearsSinceLastPromotion'] / (df['YearsAtCompany'] + 1)\n",
    "        df['YearsWithoutPromotion'] = df['YearsSinceLastPromotion']\n",
    "    \n",
    "    if 'YearsWithCurrManager' in df.columns and 'YearsAtCompany' in df.columns:\n",
    "        df['ManagerTenureRatio'] = df['YearsWithCurrManager'] / (df['YearsAtCompany'] + 1)\n",
    "    \n",
    "    # Career mobility\n",
    "    if 'NumCompaniesWorked' in df.columns and 'TotalWorkingYears' in df.columns:\n",
    "        df['AvgYearsPerCompany'] = df['TotalWorkingYears'] / (df['NumCompaniesWorked'] + 1)\n",
    "        df['JobHoppingScore'] = df['NumCompaniesWorked'] / (df['TotalWorkingYears'] + 1)\n",
    "    \n",
    "    # Satisfaction features\n",
    "    satisfaction_cols = ['JobSatisfaction', 'EnvironmentSatisfaction', 'RelationshipSatisfaction']\n",
    "    available_satisfaction = [col for col in satisfaction_cols if col in df.columns]\n",
    "    if len(available_satisfaction) >= 2:\n",
    "        df['AvgSatisfaction'] = df[available_satisfaction].mean(axis=1)\n",
    "        df['MinSatisfaction'] = df[available_satisfaction].min(axis=1)\n",
    "        df['MaxSatisfaction'] = df[available_satisfaction].max(axis=1)\n",
    "        df['SatisfactionRange'] = df['MaxSatisfaction'] - df['MinSatisfaction']\n",
    "        df['SatisfactionStd'] = df[available_satisfaction].std(axis=1)\n",
    "    \n",
    "    # Work-life balance\n",
    "    if 'DistanceFromHome' in df.columns and 'WorkLifeBalance' in df.columns:\n",
    "        df['CommuteBalanceScore'] = df['DistanceFromHome'] * df['WorkLifeBalance']\n",
    "        df['CommuteStress'] = df['DistanceFromHome'] / (df['WorkLifeBalance'] + 1)\n",
    "    \n",
    "    if 'OverTime' in df.columns:\n",
    "        df['OverTime_Binary'] = (df['OverTime'] == 'Yes').astype(int)\n",
    "    \n",
    "    # Career progression\n",
    "    if 'JobLevel' in df.columns and 'YearsAtCompany' in df.columns:\n",
    "        df['JobLevelPerYear'] = df['JobLevel'] / (df['YearsAtCompany'] + 1)\n",
    "    \n",
    "    if 'JobLevel' in df.columns and 'Age' in df.columns:\n",
    "        df['JobLevelPerAge'] = df['JobLevel'] / (df['Age'] + 1)\n",
    "    \n",
    "    # Performance\n",
    "    if 'PerformanceRating' in df.columns and 'YearsSinceLastPromotion' in df.columns:\n",
    "        df['PerformancePromotionScore'] = df['PerformanceRating'] / (df['YearsSinceLastPromotion'] + 1)\n",
    "    \n",
    "    # Training\n",
    "    if 'TrainingTimesLastYear' in df.columns and 'YearsAtCompany' in df.columns:\n",
    "        df['TrainingIntensity'] = df['TrainingTimesLastYear'] / (df['YearsAtCompany'] + 1)\n",
    "    \n",
    "    # Stagnation indicators\n",
    "    if 'YearsSinceLastPromotion' in df.columns:\n",
    "        df['LongTimeNoPromotion'] = (df['YearsSinceLastPromotion'] > 5).astype(int)\n",
    "        df['RecentPromotion'] = (df['YearsSinceLastPromotion'] <= 1).astype(int)\n",
    "    \n",
    "    if 'YearsInCurrentRole' in df.columns:\n",
    "        df['LongTimeInRole'] = (df['YearsInCurrentRole'] > 7).astype(int)\n",
    "        df['NewInRole'] = (df['YearsInCurrentRole'] <= 1).astype(int)\n",
    "    \n",
    "    # Interaction features\n",
    "    if 'JobInvolvement' in df.columns and 'JobSatisfaction' in df.columns:\n",
    "        df['JobEngagement'] = df['JobInvolvement'] * df['JobSatisfaction']\n",
    "    \n",
    "    if 'WorkLifeBalance' in df.columns and 'JobSatisfaction' in df.columns:\n",
    "        df['OverallWellbeing'] = df['WorkLifeBalance'] * df['JobSatisfaction']\n",
    "    \n",
    "    if 'EnvironmentSatisfaction' in df.columns and 'WorkLifeBalance' in df.columns:\n",
    "        df['WorkEnvironmentScore'] = df['EnvironmentSatisfaction'] * df['WorkLifeBalance']\n",
    "    \n",
    "    # Polynomial features for key metrics\n",
    "    if 'MonthlyIncome' in df.columns:\n",
    "        df['MonthlyIncome_Squared'] = df['MonthlyIncome'] ** 2\n",
    "        df['MonthlyIncome_Log'] = np.log1p(df['MonthlyIncome'])\n",
    "    \n",
    "    if 'Age' in df.columns:\n",
    "        df['Age_Squared'] = df['Age'] ** 2\n",
    "    \n",
    "    if 'DistanceFromHome' in df.columns:\n",
    "        df['Distance_Squared'] = df['DistanceFromHome'] ** 2\n",
    "    \n",
    "    # ============================================\n",
    "    # NEW ADVANCED FEATURES\n",
    "    # ============================================\n",
    "    \n",
    "    # Age-based career milestones\n",
    "    if 'Age' in df.columns:\n",
    "        df['Age_Young'] = (df['Age'] < 30).astype(int)\n",
    "        df['Age_MidCareer'] = ((df['Age'] >= 30) & (df['Age'] < 45)).astype(int)\n",
    "        df['Age_Senior'] = (df['Age'] >= 45).astype(int)\n",
    "        df['Age_Cube'] = df['Age'] ** 3\n",
    "    \n",
    "    # Income percentile features\n",
    "    if 'MonthlyIncome' in df.columns:\n",
    "        df['Income_Percentile'] = df['MonthlyIncome'].rank(pct=True)\n",
    "        df['HighEarner'] = (df['MonthlyIncome'] > df['MonthlyIncome'].quantile(0.75)).astype(int)\n",
    "        df['LowEarner'] = (df['MonthlyIncome'] < df['MonthlyIncome'].quantile(0.25)).astype(int)\n",
    "    \n",
    "    # Comprehensive satisfaction score\n",
    "    satisfaction_all = ['JobSatisfaction', 'EnvironmentSatisfaction', 'RelationshipSatisfaction', \n",
    "                        'WorkLifeBalance', 'JobInvolvement']\n",
    "    available_all = [col for col in satisfaction_all if col in df.columns]\n",
    "    if len(available_all) >= 3:\n",
    "        df['ComprehensiveSatisfaction'] = df[available_all].mean(axis=1)\n",
    "        df['LowOverallSatisfaction'] = (df['ComprehensiveSatisfaction'] < 2.5).astype(int)\n",
    "    \n",
    "    # Manager relationship longevity\n",
    "    if 'YearsWithCurrManager' in df.columns and 'YearsInCurrentRole' in df.columns:\n",
    "        df['ManagerRoleAlignment'] = abs(df['YearsWithCurrManager'] - df['YearsInCurrentRole'])\n",
    "        df['SameManagerRole'] = (df['YearsWithCurrManager'] == df['YearsInCurrentRole']).astype(int)\n",
    "    \n",
    "    # Career acceleration/deceleration\n",
    "    if 'YearsAtCompany' in df.columns and 'YearsSinceLastPromotion' in df.columns and 'JobLevel' in df.columns:\n",
    "        df['PromotionVelocity'] = df['JobLevel'] / (df['YearsAtCompany'] + 1)\n",
    "        df['CareerStuck'] = ((df['YearsSinceLastPromotion'] > 4) & (df['JobLevel'] <= 2)).astype(int)\n",
    "    \n",
    "    # Training engagement\n",
    "    if 'TrainingTimesLastYear' in df.columns:\n",
    "        df['NoTraining'] = (df['TrainingTimesLastYear'] == 0).astype(int)\n",
    "        df['HighTraining'] = (df['TrainingTimesLastYear'] >= 4).astype(int)\n",
    "        df['Training_Squared'] = df['TrainingTimesLastYear'] ** 2\n",
    "    \n",
    "    # OverTime and Income interaction\n",
    "    if 'OverTime' in df.columns and 'MonthlyIncome' in df.columns:\n",
    "        df['OvertimeIncomeLow'] = ((df['OverTime'] == 'Yes') & \n",
    "                                    (df['MonthlyIncome'] < df['MonthlyIncome'].median())).astype(int)\n",
    "    \n",
    "    # Distance categories\n",
    "    if 'DistanceFromHome' in df.columns:\n",
    "        df['Distance_VeryClose'] = (df['DistanceFromHome'] <= 5).astype(int)\n",
    "        df['Distance_VeryFar'] = (df['DistanceFromHome'] >= 20).astype(int)\n",
    "        df['Distance_Log'] = np.log1p(df['DistanceFromHome'])\n",
    "    \n",
    "    # Experience gaps and ratios\n",
    "    if 'TotalWorkingYears' in df.columns and 'YearsAtCompany' in df.columns and 'NumCompaniesWorked' in df.columns:\n",
    "        df['ExperienceGap'] = df['TotalWorkingYears'] - df['YearsAtCompany']\n",
    "        df['CompanyLoyalty'] = df['YearsAtCompany'] / (df['NumCompaniesWorked'] + 1)\n",
    "        df['FrequentJobChanger'] = (df['NumCompaniesWorked'] > 5).astype(int)\n",
    "    \n",
    "    # Stock option and job level interaction\n",
    "    if 'StockOptionLevel' in df.columns and 'JobLevel' in df.columns:\n",
    "        df['StockJobAlignment'] = df['StockOptionLevel'] * df['JobLevel']\n",
    "        df['NoStockHighLevel'] = ((df['StockOptionLevel'] == 0) & (df['JobLevel'] >= 3)).astype(int)\n",
    "    \n",
    "    # Performance and satisfaction mismatch\n",
    "    if 'PerformanceRating' in df.columns and 'JobSatisfaction' in df.columns:\n",
    "        df['PerformanceSatisfactionGap'] = abs(df['PerformanceRating'] - df['JobSatisfaction'])\n",
    "        df['HighPerfLowSat'] = ((df['PerformanceRating'] >= 3) & (df['JobSatisfaction'] <= 2)).astype(int)\n",
    "    \n",
    "    # Years ratios and complex interactions\n",
    "    if 'YearsInCurrentRole' in df.columns and 'YearsSinceLastPromotion' in df.columns:\n",
    "        df['RolePromotionGap'] = df['YearsInCurrentRole'] - df['YearsSinceLastPromotion']\n",
    "        df['LongRoleNoPromotion'] = ((df['YearsInCurrentRole'] > 5) & \n",
    "                                      (df['YearsSinceLastPromotion'] > 5)).astype(int)\n",
    "    \n",
    "    # Education and income\n",
    "    if 'Education' in df.columns and 'MonthlyIncome' in df.columns:\n",
    "        df['IncomePerEducation'] = df['MonthlyIncome'] / (df['Education'] + 1)\n",
    "    \n",
    "    # Job involvement and overtime\n",
    "    if 'JobInvolvement' in df.columns and 'OverTime' in df.columns:\n",
    "        df['LowInvolvementOvertime'] = ((df['JobInvolvement'] <= 2) & \n",
    "                                        (df['OverTime'] == 'Yes')).astype(int)\n",
    "    \n",
    "    # Age and experience alignment\n",
    "    if 'Age' in df.columns and 'TotalWorkingYears' in df.columns:\n",
    "        df['LateCareerStart'] = ((df['Age'] - df['TotalWorkingYears']) > 25).astype(int)\n",
    "        df['EarlyCareerStart'] = ((df['Age'] - df['TotalWorkingYears']) < 20).astype(int)\n",
    "    \n",
    "    # Multi-way interactions\n",
    "    if 'MonthlyIncome' in df.columns and 'JobLevel' in df.columns and 'YearsAtCompany' in df.columns:\n",
    "        df['IncomeJobYears'] = (df['MonthlyIncome'] * df['JobLevel']) / (df['YearsAtCompany'] + 1)\n",
    "    \n",
    "    if 'DistanceFromHome' in df.columns and 'OverTime' in df.columns and 'WorkLifeBalance' in df.columns:\n",
    "        df['CommuteOvertimeBalance'] = (df['DistanceFromHome'] * \n",
    "                                        (df['OverTime'] == 'Yes').astype(int)) / (df['WorkLifeBalance'] + 1)\n",
    "    \n",
    "    # Job hopping with age\n",
    "    if 'NumCompaniesWorked' in df.columns and 'Age' in df.columns:\n",
    "        df['JobHoppingPerAge'] = df['NumCompaniesWorked'] / (df['Age'] + 1)\n",
    "        df['StableCareer'] = ((df['NumCompaniesWorked'] <= 2) & (df['Age'] >= 35)).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "print(\"\\nApplying advanced feature engineering...\")\n",
    "combined_df = create_advanced_features(combined_df)\n",
    "print(f\"Features after engineering: {combined_df.shape[1]}\")\n",
    "\n",
    "# Split back to train and test\n",
    "train_engineered = combined_df[combined_df['is_train'] == 1].drop(columns=['is_train']).reset_index(drop=True)\n",
    "test_engineered = combined_df[combined_df['is_train'] == 0].drop(columns=['is_train']).reset_index(drop=True)\n",
    "\n",
    "# Split features and target\n",
    "X = train_engineered.drop(columns=[target_col])\n",
    "y = train_engineered[target_col]\n",
    "X_test = test_engineered.drop(columns=[target_col], errors='ignore')\n",
    "\n",
    "# Identify feature types\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# Remove ID column\n",
    "if id_col in numeric_features:\n",
    "    numeric_features.remove(id_col)\n",
    "if id_col in categorical_features:\n",
    "    categorical_features.remove(id_col)\n",
    "\n",
    "print(f\"\\nNumeric features: {len(numeric_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")\n",
    "\n",
    "# Preprocessing\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "# Transform data\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Split for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_transformed, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BUILDING OPTIMIZED SUPER ENSEMBLE WITH 6 MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define models with fine-tuned hyperparameters\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=1500,\n",
    "        learning_rate=0.02,\n",
    "        max_depth=8,\n",
    "        min_child_weight=2,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        gamma=0.15,\n",
    "        reg_alpha=0.2,\n",
    "        reg_lambda=1.5,\n",
    "        scale_pos_weight=3,  # Handle class imbalance\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss'\n",
    "    ),\n",
    "    'LightGBM': LGBMClassifier(\n",
    "        n_estimators=1500,\n",
    "        learning_rate=0.02,\n",
    "        max_depth=8,\n",
    "        num_leaves=40,\n",
    "        subsample=0.85,\n",
    "        colsample_bytree=0.85,\n",
    "        reg_alpha=0.2,\n",
    "        reg_lambda=1.5,\n",
    "        min_child_samples=25,\n",
    "        is_unbalance=True,  # Handle class imbalance\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    ),\n",
    "    'CatBoost': CatBoostClassifier(\n",
    "        iterations=1500,\n",
    "        learning_rate=0.02,\n",
    "        depth=8,\n",
    "        l2_leaf_reg=2,\n",
    "        border_count=128,\n",
    "        random_strength=0.5,\n",
    "        auto_class_weights='Balanced',  # Handle class imbalance\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    ),\n",
    "    'RandomForest': RandomForestClassifier(\n",
    "        n_estimators=1200,\n",
    "        max_depth=25,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        max_features='sqrt',\n",
    "        bootstrap=True,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced_subsample'\n",
    "    ),\n",
    "    'ExtraTrees': ExtraTreesClassifier(\n",
    "        n_estimators=1200,\n",
    "        max_depth=25,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        max_features='sqrt',\n",
    "        bootstrap=True,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight='balanced_subsample'\n",
    "    ),\n",
    "    'GradientBoosting': GradientBoostingClassifier(\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=7,\n",
    "        min_samples_split=3,\n",
    "        min_samples_leaf=2,\n",
    "        subsample=0.85,\n",
    "        max_features='sqrt',\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train and evaluate individual models\n",
    "print(\"\\nTraining individual models...\")\n",
    "individual_preds = {}\n",
    "val_accuracies = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_acc = accuracy_score(y_val, val_pred)\n",
    "    val_accuracies[name] = val_acc\n",
    "    print(f\"{name} Validation Accuracy: {val_acc:.6f}\")\n",
    "    \n",
    "    # Store predictions\n",
    "    individual_preds[name] = val_pred\n",
    "\n",
    "# Ensemble prediction using voting\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING WEIGHTED VOTING ENSEMBLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Retrain on full training data\n",
    "print(\"\\nRetraining all models on full data...\")\n",
    "final_preds = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_transformed, y)\n",
    "    test_pred = model.predict(X_test_transformed)\n",
    "    final_preds[name] = test_pred\n",
    "    print(f\"{name} trained\")\n",
    "\n",
    "# Weighted voting based on validation accuracy\n",
    "weights = np.array([val_accuracies[name] for name in models.keys()])\n",
    "weights = weights / weights.sum()\n",
    "\n",
    "print(\"\\nModel Weights:\")\n",
    "for name, weight in zip(models.keys(), weights):\n",
    "    print(f\"  {name}: {weight:.4f} (Val Acc: {val_accuracies[name]:.6f})\")\n",
    "\n",
    "# Create final predictions using weighted voting\n",
    "final_pred_array = np.array([final_preds[name] for name in models.keys()])\n",
    "weighted_votes = np.average(final_pred_array, axis=0, weights=weights)\n",
    "final_predictions = (weighted_votes > 0.5).astype(int)\n",
    "\n",
    "# Calculate ensemble validation accuracy\n",
    "val_pred_array = np.array([individual_preds[name] for name in models.keys()])\n",
    "val_weighted_votes = np.average(val_pred_array, axis=0, weights=weights)\n",
    "ensemble_val_pred = (val_weighted_votes > 0.5).astype(int)\n",
    "ensemble_val_acc = accuracy_score(y_val, ensemble_val_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"ENSEMBLE VALIDATION ACCURACY: {ensemble_val_acc:.6f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    id_col: test_df[id_col],\n",
    "    target_col: final_predictions,\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_test2_optimized.csv\", index=False)\n",
    "print(f\"\\nSubmission saved: submission_test2_optimized.csv ({len(submission)} rows)\")\n",
    "print(f\"Prediction distribution:\\n{pd.Series(final_predictions).value_counts()}\")\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
